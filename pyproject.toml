[project]
name = "mads-ml-maxn"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "mads-datasets>=0.3.14",
    "marimo>=0.15.3",
    "mltrainer>=0.2.5",
    "seaborn>=0.13.2",
    "tensorboard>=2.20.0",
    "tomlserializer>=0.2.0",
    "torch-tb-profiler>=0.4.3",
]

[project.optional-dependencies]
cpu = ["torch>=2.8.0", "torchvision>=0.22.0"]
xpu = [
    "torch>=2.8.0",
    "torchvision>=0.22.0",
    "pytorch-triton-xpu>=3.3.0 ; sys_platform == 'win32' or sys_platform == 'linux'",
]
cu129 = ["torch>=2.8.0", "torchvision>=0.22.0"]

[tool.uv]
conflicts = [[{ extra = "cpu" }, { extra = "xpu" }, { extra = "cu129" }]]

[tool.uv.sources]
torch = [
    { index = "pytorch-cpu", extra = "cpu" },
    { index = "pytorch-xpu", extra = "xpu" },
    { index = "pytorch-cu129", extra = "cu129" },
]
torchvision = [
    { index = "pytorch-cpu", extra = "cpu" },
    { index = "pytorch-xpu", extra = "xpu" },
    { index = "pytorch-cu129", extra = "cu129" },
]
# Intel GPU support relies on `pytorch-triton-xpu`, which should also be installed from the PyTorch index
# (and included in `project.dependencies`).
pytorch-triton-xpu = [{ index = "pytorch-xpu", extra = "xpu" }]

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[[tool.uv.index]]
name = "pytorch-xpu"
url = "https://download.pytorch.org/whl/xpu"
explicit = true

[[tool.uv.index]]
name = "pytorch-cu129"
url = "https://download.pytorch.org/whl/cu129"
explicit = true


[tool.marimo.runtime]
auto_instantiate = false
